{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIMS Watershed Query: AnnAGNPS files preparation\n",
    "This notebook replicates the data flow of what a user would do when clicking on the AIMS web interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "import pyagnps\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sqlalchemy import URL, create_engine, text as sql_text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User input here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watershed_name = 'Pelahatchie Creek'\n",
    "# watershed_description = 'As generated by AIMS'\n",
    "# watershed_location = ''\n",
    "\n",
    "watershed_name = 'Upper Pearl River Basin'\n",
    "watershed_description = 'As generated by AIMS'\n",
    "watershed_location = 'Mississippi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlet coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon, lat = -89.92829, 32.52256 # Upper Pearl River upstream of reservoir\n",
    "# lon, lat = -89.96793, 32.38881 # Pelahatchie Creek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time bounds and climate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_method = 'nldas2' # valid options ares 'nldas2', 'cmip5'\n",
    "\n",
    "# Time period in YYYY-MM-DD format (both bounds included)\n",
    "startDate=\"2010-01-01\" \n",
    "endDate=\"2022-12-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_folder = Path('C:/Users/Luc/Desktop/pelahatchie_creek')\n",
    "output_folder = Path('C:/Users/Luc/Desktop/UpperPearlRiverBasin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths to useful static files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database credentials\n",
    "credentials = Path(\"../../inputs/db_credentials.json\")\n",
    "\n",
    "# GeoPackage that contains the centroid of each NLDAS-2 grid\n",
    "path_nldas_grid_centroids = Path(\"D:/AIMS/Datasets/Climate/NLDAS2/NLDAS2_GRID_CENTROIDS_epsg4326.gpkg\")\n",
    "# path_nldas_grid_centroids = Path(\"C:/Users/Luc/projects/pyagnps/inputs/climate/NLDAS2_GRID_CENTROIDS_epsg4326.gpkg\")\n",
    "\n",
    "# Path to root folder containing variables of the CMIP5 MACAv2METDATA\n",
    "path_to_cmip5_historical_and_rcp45 = Path(\"D:/AIMS/Datasets/Climate/CMIP/CMIP5/MACAv2METDATA/CNRM-CM5/r1i1p1/\")\n",
    "path_to_cmip5_raster_points_clim_id = path_to_cmip5_historical_and_rcp45 / \"cmip5_maca_v2_metdata_pts_clim_ids.gpkg\"\n",
    "\n",
    "# Path to SCS Storm Types\n",
    "path_to_scs_storm_types = Path('D:/AIMS/Datasets/Climate/TR-55/scs_storm_types.gpkg')\n",
    "\n",
    "# Path to RUSLE2 Precipitation Zones\n",
    "path_to_precip_zones = Path('D:/AIMS/Datasets/Management/RUSLE2_Climate/RUSLE2-Climate-Data-20231117/precip_zones_RUSLE2_cleaned_manually_extrapolated_pchip_linear_US_units.gpkg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main process starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATABASE SETUP\n",
    "with open(credentials, \"r\") as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "user = credentials[\"user\"]\n",
    "password = credentials[\"password\"]\n",
    "host = credentials[\"host\"]\n",
    "port = credentials[\"port\"]\n",
    "database = credentials[\"database\"]\n",
    "\n",
    "url_object = URL.create(\n",
    "    \"postgresql\",\n",
    "    username=user,\n",
    "    password=password,\n",
    "    host=host,\n",
    "    port=port,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "# create a SQLAlchemy engine object\n",
    "engine = create_engine(url_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "def make_annagnps_inputs_dirs(output_folder, subdirs=['general', 'climate', 'simulation', 'watershed', 'GIS']):\n",
    "    subdirs_paths = []\n",
    "    for subdir in subdirs:\n",
    "        category_dir = output_folder / subdir\n",
    "        category_dir.mkdir(exist_ok=True)\n",
    "        subdirs_paths.append(category_dir)\n",
    "    return subdirs_paths\n",
    "        \n",
    "\n",
    "general_dir, \\\n",
    "climate_dir, \\\n",
    "simulation_dir, \\\n",
    "watershed_dir, \\\n",
    "gis_dir = make_annagnps_inputs_dirs(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify T-HUC containing the watershed of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc = pd.read_sql_query(sql_text(f\"SELECT thuc_near_run_id_tr({lon},{lat})\"),con=engine.connect())\n",
    "thuc_id = thuc.iloc[0].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query reach and cell data sections along with their geometries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cells geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_query = f\"SELECT geom, cell_id FROM thuc_cell_geo_tr({lon},{lat}, '{thuc_id}')\"\n",
    "\n",
    "cells_geometry = gpd.read_postgis(sql=sql_text(cells_query), con=engine.connect(), geom_col='geom')\n",
    "cells_list = cells_geometry['cell_id'].unique() # List of cell_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reach Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaches_query = f\"SELECT geom, reach_id FROM thuc_reach_geo_tr({lon},{lat}, '{thuc_id}')\"\n",
    "\n",
    "reaches_geometry = gpd.read_postgis(sql=sql_text(reaches_query), con=engine.connect(), geom_col='geom')\n",
    "reaches_list = reaches_geometry['reach_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell Data Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM thuc_{thuc_id}_annagnps_cell_data_section WHERE cell_id in {*cells_list,}\"\n",
    "\n",
    "df_cells = pd.read_sql_query(sql=sql_text(query), con=engine.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reach Data Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM thuc_{thuc_id}_annagnps_reach_data_section WHERE reach_id in {*reaches_list,}\"\n",
    "\n",
    "df_reaches = pd.read_sql_query(sql=sql_text(query), con=engine.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make reach data section \"valid\" for AnnAGNPS i.e. add an \"OUTLET\" row at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_reaches_valid(df_reaches):\n",
    "    reaches = set(df_reaches['reach_id'])\n",
    "    receiving_reaches = set(df_reaches['receiving_reach'])\n",
    "\n",
    "    outlet_reach = list(receiving_reaches - reaches)[0]\n",
    "    # print(f\"Outlet reach: {outlet_reach}\")\n",
    "\n",
    "    outlet_row = df_reaches[df_reaches['receiving_reach']==outlet_reach].copy()\n",
    "    outlet_row['reach_id'] = outlet_reach\n",
    "    outlet_row['receiving_reach'] = 'OUTLET'\n",
    "    outlet_row['length'] = 0\n",
    "\n",
    "    df_reaches_valid = pd.concat([outlet_row, df_reaches], ignore_index=True)\n",
    "    return df_reaches_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reaches_valid = make_df_reaches_valid(df_reaches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join data sections with their respective geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_geometry = cells_geometry.merge(df_cells, on='cell_id')\n",
    "reaches_geometry = reaches_geometry.merge(df_reaches, on='reach_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Soil data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query soil_data and soil_layers_daya for matching soil_id as well as raw soil data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_ids_list = df_cells['soil_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_soil = f\"\"\"SELECT * FROM usa_valid_soil_data WHERE \"Soil_ID\" in {*soil_ids_list,}\"\"\"\n",
    "query_soil_layers = f\"\"\"SELECT * FROM usa_valid_soil_layers_data WHERE \"Soil_ID\" in {*soil_ids_list,}\"\"\"\n",
    "query_raw = f\"\"\"SELECT * FROM raw_nrcs_soil_data WHERE \"mukey\" in {*soil_ids_list,}\"\"\"\n",
    "\n",
    "df_soil_data = pd.read_sql_query(sql=sql_text(query_soil), con=engine.connect())\n",
    "\n",
    "df_soil_layers_data = pd.read_sql_query(sql=sql_text(query_soil_layers), con=engine.connect())\n",
    "df_soil_layers_data = df_soil_layers_data.sort_values(by=['Soil_ID','Layer_Number'])\n",
    "\n",
    "df_raw = pd.read_sql_query(sql=sql_text(query_raw), con=engine.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Management Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Management Field IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt_field_ids_list = df_cells['mgmt_field_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field_ID</th>\n",
       "      <th>Landuse_Type_ID</th>\n",
       "      <th>Mgmt_Schd_ID</th>\n",
       "      <th>Greg_Yr_for_1st_Yr_of_Rotation</th>\n",
       "      <th>Percent_Rock_Cover</th>\n",
       "      <th>Interrill_Erosion_Code</th>\n",
       "      <th>Random_Roughness</th>\n",
       "      <th>Terrace_Horizontal_Distance</th>\n",
       "      <th>Terrace_Grade</th>\n",
       "      <th>Tile_Drain_ID</th>\n",
       "      <th>Input_Units_Code</th>\n",
       "      <th>CDL_Category</th>\n",
       "      <th>CDL_Value</th>\n",
       "      <th>Modified_CDL_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corn</td>\n",
       "      <td>CROPLAND</td>\n",
       "      <td>Corn</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Corn</td>\n",
       "      <td>1</td>\n",
       "      <td>Corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cotton</td>\n",
       "      <td>CROPLAND</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>2</td>\n",
       "      <td>Cotton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dbl_Crop_WinWht_Corn</td>\n",
       "      <td>CROPLAND</td>\n",
       "      <td>Dbl_Crop_WinWht_Corn</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Dbl Crop WinWht/Corn</td>\n",
       "      <td>225</td>\n",
       "      <td>Dbl_Crop_WinWht_Corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dbl_Crop_WinWht_Soybeans</td>\n",
       "      <td>CROPLAND</td>\n",
       "      <td>Dbl_Crop_WinWht_Soybeans</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Dbl Crop WinWht/Soybeans</td>\n",
       "      <td>26</td>\n",
       "      <td>Dbl_Crop_WinWht_Soybeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Developed_Open_Space</td>\n",
       "      <td>URBAN</td>\n",
       "      <td>Developed_Open_Space</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Developed/Open Space</td>\n",
       "      <td>121</td>\n",
       "      <td>Developed_Open_Space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Field_ID Landuse_Type_ID              Mgmt_Schd_ID  \\\n",
       "0                      Corn        CROPLAND                      Corn   \n",
       "1                    Cotton        CROPLAND                    Cotton   \n",
       "2      Dbl_Crop_WinWht_Corn        CROPLAND      Dbl_Crop_WinWht_Corn   \n",
       "3  Dbl_Crop_WinWht_Soybeans        CROPLAND  Dbl_Crop_WinWht_Soybeans   \n",
       "4      Developed_Open_Space           URBAN      Developed_Open_Space   \n",
       "\n",
       "  Greg_Yr_for_1st_Yr_of_Rotation Percent_Rock_Cover Interrill_Erosion_Code  \\\n",
       "0                           None               None                   None   \n",
       "1                           None               None                   None   \n",
       "2                           None               None                   None   \n",
       "3                           None               None                   None   \n",
       "4                           None               None                   None   \n",
       "\n",
       "  Random_Roughness Terrace_Horizontal_Distance Terrace_Grade Tile_Drain_ID  \\\n",
       "0             None                        None          None          None   \n",
       "1             None                        None          None          None   \n",
       "2             None                        None          None          None   \n",
       "3             None                        None          None          None   \n",
       "4             None                        None          None          None   \n",
       "\n",
       "   Input_Units_Code              CDL_Category  CDL_Value  \\\n",
       "0                 1                      Corn          1   \n",
       "1                 1                    Cotton          2   \n",
       "2                 1      Dbl Crop WinWht/Corn        225   \n",
       "3                 1  Dbl Crop WinWht/Soybeans         26   \n",
       "4                 1      Developed/Open Space        121   \n",
       "\n",
       "      Modified_CDL_Category  \n",
       "0                      Corn  \n",
       "1                    Cotton  \n",
       "2      Dbl_Crop_WinWht_Corn  \n",
       "3  Dbl_Crop_WinWht_Soybeans  \n",
       "4      Developed_Open_Space  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_mgmt_field_data = f\"\"\"SELECT * FROM annagnps_mgmt_field WHERE \"Field_ID\" in {*mgmt_field_ids_list,}\"\"\"\n",
    "df_mgmt_field = pd.read_sql_query(sql=sql_text(query_mgmt_field_data), con=engine.connect())\n",
    "df_mgmt_field.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get matching Management Schedule IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt_schedule_ids_list = df_mgmt_field['Mgmt_Schd_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_mgmt_field_data = f\"\"\"SELECT * FROM annagnps_mgmt_schd WHERE \"Mgmt_Schd_ID\" in {*mgmt_schedule_ids_list,}\"\"\"\n",
    "df_mgmt_schd = pd.read_sql_query(sql=sql_text(query_mgmt_field_data), con=engine.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get matching Crop, Non-Crop, Management Operation, and Runoff Curve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt_crop_ids_list     = df_mgmt_schd['New_Crop_ID'].dropna().unique()\n",
    "mgmt_non_crop_ids_list = df_mgmt_schd['New_Non-Crop_ID'].dropna().unique()\n",
    "mgmt_oper_ids_list     = df_mgmt_schd['Mgmt_Operation_ID'].dropna().unique()\n",
    "roc_ids_list           = df_mgmt_schd['Curve_Number_ID'].dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_mgmt_crop_data        = f\"\"\"SELECT * FROM annagnps_crop WHERE \"Crop_ID\" in {*mgmt_crop_ids_list,}\"\"\"\n",
    "query_mgmt_crop_growth_data = f\"\"\"SELECT * FROM annagnps_crop_growth WHERE \"Crop_Growth_ID\" in {*mgmt_crop_ids_list,}\"\"\"\n",
    "\n",
    "query_mgmt_non_crop_data    = f\"\"\"SELECT * FROM annagnps_non_crop WHERE \"Non-Crop_ID\" in {*mgmt_non_crop_ids_list,}\"\"\"\n",
    "query_mgmt_oper_data        = f\"\"\"SELECT * FROM annagnps_mgmt_oper WHERE \"Mgmt_Operation_ID\" in {*mgmt_oper_ids_list,}\"\"\"\n",
    "\n",
    "query_roc_data              = f\"\"\"SELECT * FROM annagnps_runoff_curve WHERE \"Curve_Number_ID\" in {*roc_ids_list,}\"\"\"\n",
    "\n",
    "df_mgmt_crop        = pd.read_sql_query(sql=sql_text(query_mgmt_crop_data), con=engine.connect())\n",
    "df_mgmt_crop_growth = pd.read_sql_query(sql=sql_text(query_mgmt_crop_growth_data), con=engine.connect())\n",
    "df_mgmt_non_crop    = pd.read_sql_query(sql=sql_text(query_mgmt_non_crop_data), con=engine.connect())\n",
    "df_mgmt_oper        = pd.read_sql_query(sql=sql_text(query_mgmt_oper_data), con=engine.connect())\n",
    "df_roc              = pd.read_sql_query(sql=sql_text(query_roc_data), con=engine.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watershed scale variables - Simulation Period Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Water boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = cells_geometry[['geom']].copy(deep=True)\n",
    "bounds.geometry = bounds.geometry.buffer(0.00001)\n",
    "bounds = bounds.dissolve()\n",
    "bounds = bounds.to_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Watershed SCS Storm Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scs_storm_types = gpd.read_file(path_to_scs_storm_types)\n",
    "scs_storm_types = scs_storm_types.to_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_scs = bounds.overlay(scs_storm_types)\n",
    "bounds_scs['area'] = bounds_scs.geometry.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_storm_type = bounds_scs.loc[bounds_scs['area'].argmax(), 'SCS Zone Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10_Year_EI, EI_Zone, R_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_zones = gpd.read_file(path_to_precip_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_precip = bounds.overlay(precip_zones)\n",
    "bounds_precip['area'] = bounds_precip.geometry.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_R_fctr = (bounds_precip['area'] * bounds_precip['R_factor']).sum() / bounds_precip['area'].sum()\n",
    "weighted_10_year_EI = (bounds_precip['area'] * bounds_precip['10_year_EI']).sum() / bounds_precip['area'].sum()\n",
    "\n",
    "dominant_EI = bounds_precip.loc[bounds_precip['area'].argmax(), 'EI_Zone']\n",
    "\n",
    "if dominant_EI == 'default':\n",
    "    dominant_EI = pyagnps.constants.DEFAULT_EI_NUMBER # 100 \n",
    "else:\n",
    "    dominant_EI = int(dominant_EI.replace('US_',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watershed Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "WATERSHED_DATA = {\n",
    "    'Wshd_Name': watershed_name,\n",
    "    'Wshd_Description': watershed_description,\n",
    "    'Wshd_Location': watershed_location,\n",
    "    'Latitude': lat,\n",
    "    'Longitude': lon\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate climate files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get watershed centroid computed in terms of lat and lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /!\\ This centroid is computed in degrees coordinates\n",
    "lon0, lat0 = cells_geometry.dissolve().centroid.x[0], cells_geometry.dissolve().centroid.y[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset cells secondary climate file id (just in case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_geometry['secondary_climate_file_id'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using NLDAS-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the NLDAS-2 grid ID nearest to each cell and populate it in the `secondary_climate_file_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if climate_method == 'nldas2':\n",
    "    nldas_centroids = gpd.read_file(path_nldas_grid_centroids)\n",
    "    cells_geometry = cells_geometry.sjoin_nearest(nldas_centroids)\n",
    "    cells_geometry['secondary_climate_file_id'] = cells_geometry['nldas2_grid_ID']\n",
    "    cells_geometry.drop(columns=['nldas2_grid_ID', 'index_right'], inplace=True)\n",
    "\n",
    "    secondary_climate_ids = cells_geometry.loc[:,['cell_id', 'secondary_climate_file_id']]\\\n",
    "                            .drop_duplicates(subset='cell_id')\\\n",
    "                            .set_index('cell_id')\n",
    "    \n",
    "    # Generate climate data for the unique NLDAS-2 grid ID featuring in the watershed \n",
    "    climate_station_points = nldas_centroids[nldas_centroids['nldas2_grid_ID'].isin(cells_geometry['secondary_climate_file_id'].unique())]\n",
    "    climate_station_points = climate_station_points.to_crs('epsg:4326')\n",
    "\n",
    "    # Update df_cells with data in secondary_climate_ids\n",
    "    if df_cells.index.name != 'cell_id':\n",
    "        df_cells = df_cells.set_index('cell_id')\n",
    "\n",
    "    df_cells.update(secondary_climate_ids)\n",
    "    df_cells = df_cells.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using CMIP5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CMIP5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if climate_method == 'cmip5':\n",
    "    clm = pyagnps.climate.ClimateAnnAGNPSCoords(coords=None,\n",
    "                                                start=startDate,\n",
    "                                                end=endDate)\n",
    "\n",
    "    clm.read_cmip5_maca_data(path_to_cmip5_historical_and_rcp45.glob(\"*/*.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate or load geopackage file containing the centroids of each raster points of the CMIP5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if climate_method == 'cmip5':\n",
    "    if path_to_cmip5_raster_points_clim_id.exists():\n",
    "        print('Reading points and clim_id of CMIP5 MACAv2METDATA')\n",
    "        cmip_pts = gpd.read_file(path_to_cmip5_raster_points_clim_id)\n",
    "    else:\n",
    "        # Generate all the possible pairs of points\n",
    "        print('Generating points and clim_id of CMIP5 MACAv2METDATA')\n",
    "        lat_vals = clm.ds['lat'].values\n",
    "        lon_vals = clm.ds['lon'].values - 360 # For CMIP6 and CMIP5 the longitude needs to be in the [0, 360[ range, here we bring it back in the -180, 180\n",
    "\n",
    "        all_lon_lat_pairs = list(itertools.product(lon_vals, lat_vals))\n",
    "\n",
    "        lon_values, lat_values = zip(*all_lon_lat_pairs)\n",
    "\n",
    "        pts = gpd.points_from_xy(x=lon_values, y=lat_values, crs=4326)\n",
    "        cmip_pts = gpd.GeoDataFrame(geometry=pts, crs=4326)\n",
    "\n",
    "        cmip_pts['clim_id'] = cmip_pts['geometry'].apply(lambda geom: clm.generate_cmip_lon_lat_secondary_climate_id((geom.x, geom.y)))\n",
    "\n",
    "        cmip_pts.to_file(path_to_cmip5_raster_points_clim_id, driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning secondary climate id for every cell based on the CMIP5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if climate_method == 'cmip5':\n",
    "\n",
    "    cells_geometry = cells_geometry.sjoin_nearest(cmip_pts)\n",
    "    cells_geometry['secondary_climate_file_id'] = cells_geometry['clim_id']\n",
    "    cells_geometry.drop(columns=['clim_id', 'index_right'], inplace=True)\n",
    "\n",
    "\n",
    "    secondary_climate_ids = cells_geometry.loc[:,['cell_id', 'secondary_climate_file_id']]\\\n",
    "                                .drop_duplicates(subset='cell_id')\\\n",
    "                                .set_index('cell_id')\n",
    "    \n",
    "    # List of points for which to extract the climate data for this watershed\n",
    "    climate_station_points = cmip_pts[cmip_pts['clim_id'].isin(secondary_climate_ids['secondary_climate_file_id'])]\n",
    "    climate_station_points = climate_station_points.to_crs('epsg:4326')\n",
    "\n",
    "    # Update df_cells with data in secondary_climate_ids\n",
    "    if df_cells.index.name != 'cell_id':\n",
    "        df_cells = df_cells.set_index('cell_id')\n",
    "\n",
    "    df_cells.update(secondary_climate_ids)\n",
    "    df_cells = df_cells.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate climate data dictionary for selected climate source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 27/64 [09:53<13:33, 21.98s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Timestamp('2022-12-31 06:00:00')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mindex.pyx:598\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1672466400000000000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Luc\\projects\\pyagnps\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:566\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:600\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: Timestamp('2022-12-31 06:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Luc\\projects\\pyagnps\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:631\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Luc\\projects\\pyagnps\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: Timestamp('2022-12-31 06:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     climate_station_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNLDAS-2 Grid ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclim_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m     clm \u001b[38;5;241m=\u001b[39m pyagnps\u001b[38;5;241m.\u001b[39mclimate\u001b[38;5;241m.\u001b[39mClimateAnnAGNPSCoords(coords\u001b[38;5;241m=\u001b[39m(x,y), start\u001b[38;5;241m=\u001b[39mstartDate, end\u001b[38;5;241m=\u001b[39mendDate, date_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mclm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_nldas2_generate_annagnps_climate_daily\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m climate_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcmip5\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     15\u001b[0m     clim_id \u001b[38;5;241m=\u001b[39m feature[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclim_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\projects\\pyagnps\\src\\pyagnps\\climate.py:252\u001b[0m, in \u001b[0;36mClimateAnnAGNPSCoords.query_nldas2_generate_annagnps_climate_daily\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoords:\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoordinates are missing. Please provide coords!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 252\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_nldas2_climate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnetcdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Test if there are any NaN values\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclm\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Use alternative method using Day Met\u001b[39;00m\n",
      "File \u001b[1;32m~\\projects\\pyagnps\\src\\pyagnps\\climate.py:142\u001b[0m, in \u001b[0;36mClimateAnnAGNPSCoords._query_nldas2_climate\u001b[1;34m(self, source, variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_query_nldas2_climate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    130\u001b[0m     source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetcdf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m     ],\n\u001b[0;32m    141\u001b[0m ):\n\u001b[1;32m--> 142\u001b[0m     clm \u001b[38;5;241m=\u001b[39m \u001b[43mpynldas2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bycoords\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;66;03m# Express dates in local mode\u001b[39;00m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdate_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Luc\\projects\\pyagnps\\.venv\\Lib\\site-packages\\pynldas2\\pynldas2.py:458\u001b[0m, in \u001b[0;36mget_bycoords\u001b[1;34m(coords, start_date, end_date, coords_id, crs, variables, to_xarray, n_conn, snow, snow_params, source)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clm_ds\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_pts \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 458\u001b[0m     clm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(clm_list), pd\u001b[38;5;241m.\u001b[39mDataFrame())\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     clm \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(clm_list, keys\u001b[38;5;241m=\u001b[39midx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Luc\\projects\\pyagnps\\.venv\\Lib\\site-packages\\pynldas2\\pynldas2.py:351\u001b[0m, in \u001b[0;36m_byloc\u001b[1;34m(lon, lat, start_date, end_date, variables, n_conn, snow, snow_params, source)\u001b[0m\n\u001b[0;32m    349\u001b[0m clm\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    350\u001b[0m clm\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(clm\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Luc\\projects\\pyagnps\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Luc\\projects\\pyagnps\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1373\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   1372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_slice_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getbool_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\Luc\\projects\\pyagnps\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1405\u001b[0m, in \u001b[0;36m_LocIndexer._get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1404\u001b[0m labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1405\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   1408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\Luc\\projects\\pyagnps\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:683\u001b[0m, in \u001b[0;36mDatetimeIndex.slice_indexer\u001b[1;34m(self, start, end, step)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;66;03m# GH#33146 if start and end are combinations of str and None and Index is not\u001b[39;00m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;66;03m# monotonic, we can not use Index.slice_indexer because it does not honor the\u001b[39;00m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;66;03m# actual elements, is only searching for start and end\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    679\u001b[0m     check_str_or_none(start)\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m check_str_or_none(end)\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_monotonic_increasing\n\u001b[0;32m    682\u001b[0m ):\n\u001b[1;32m--> 683\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    685\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    686\u001b[0m in_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Luc\\projects\\pyagnps\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6601\u001b[0m, in \u001b[0;36mIndex.slice_indexer\u001b[1;34m(self, start, end, step)\u001b[0m\n\u001b[0;32m   6557\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_indexer\u001b[39m(\n\u001b[0;32m   6558\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   6559\u001b[0m     start: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   6560\u001b[0m     end: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   6561\u001b[0m     step: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   6562\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mslice\u001b[39m:\n\u001b[0;32m   6563\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6564\u001b[0m \u001b[38;5;124;03m    Compute the slice indexer for input labels and step.\u001b[39;00m\n\u001b[0;32m   6565\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6599\u001b[0m \u001b[38;5;124;03m    slice(1, 3, None)\u001b[39;00m\n\u001b[0;32m   6600\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6601\u001b[0m     start_slice, end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_locs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6603\u001b[0m     \u001b[38;5;66;03m# return a slice\u001b[39;00m\n\u001b[0;32m   6604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(start_slice):\n",
      "File \u001b[1;32mc:\\Users\\Luc\\projects\\pyagnps\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6824\u001b[0m, in \u001b[0;36mIndex.slice_locs\u001b[1;34m(self, start, end, step)\u001b[0m\n\u001b[0;32m   6822\u001b[0m end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   6823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 6824\u001b[0m     end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_slice_bound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mright\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end_slice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   6826\u001b[0m     end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Luc\\projects\\pyagnps\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6743\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[1;34m(self, label, side)\u001b[0m\n\u001b[0;32m   6740\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_searchsorted_monotonic(label, side)\n\u001b[0;32m   6741\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   6742\u001b[0m         \u001b[38;5;66;03m# raise the original KeyError\u001b[39;00m\n\u001b[1;32m-> 6743\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m   6745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(slc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   6746\u001b[0m     \u001b[38;5;66;03m# get_loc may return a boolean array, which\u001b[39;00m\n\u001b[0;32m   6747\u001b[0m     \u001b[38;5;66;03m# is OK as long as they are representable by a slice.\u001b[39;00m\n\u001b[0;32m   6748\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m is_bool_dtype(slc\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\Luc\\projects\\pyagnps\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6737\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[1;34m(self, label, side)\u001b[0m\n\u001b[0;32m   6735\u001b[0m \u001b[38;5;66;03m# we need to look up the label\u001b[39;00m\n\u001b[0;32m   6736\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 6737\u001b[0m     slc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6738\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   6739\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Luc\\projects\\pyagnps\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:633\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Index\u001b[38;5;241m.\u001b[39mget_loc(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 633\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(orig_key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: Timestamp('2022-12-31 06:00:00')"
     ]
    }
   ],
   "source": [
    "climate_data = {}\n",
    "\n",
    "for feature in tqdm(climate_station_points.iterfeatures(), total=len(climate_station_points)):\n",
    "\n",
    "    x, y = feature['geometry']['coordinates']\n",
    "\n",
    "    if climate_method == 'nldas2':\n",
    "        clim_id = feature['properties']['nldas2_grid_ID']\n",
    "        climate_station_name = f\"NLDAS-2 Grid ID {clim_id}\"\n",
    "\n",
    "        clm = pyagnps.climate.ClimateAnnAGNPSCoords(coords=(x,y), start=startDate, end=endDate, date_mode=\"local\")\n",
    "        df = clm.query_nldas2_generate_annagnps_climate_daily()\n",
    "        \n",
    "    elif climate_method == 'cmip5':\n",
    "        clim_id = feature['properties']['clim_id']\n",
    "        climate_station_name = f\"CMIP5 MACAv2METDATA raster ID {clim_id}\"\n",
    "        \n",
    "        clm.update_coords_start_end_dates(coords=(x,y), start=startDate, end=endDate, date_mode=\"local\")\n",
    "        df = clm.generate_annagnps_daily_climate_data_cmip5_maca()\n",
    "        \n",
    "\n",
    "    climate_data[clim_id] = {\n",
    "        'data': df, # DataFrame containing the climate data\n",
    "        'climate_station': { # Climate station metadata\n",
    "            'output_filepath': climate_dir / f'climate_station_{clim_id}.csv',\n",
    "            'climate_station_name': climate_station_name,\n",
    "            'beginning_climate_date': clm.start.strftime(\"%m/%d/%Y\"),\n",
    "            'ending_climate_date': clm.end.strftime(\"%m/%d/%Y\"),\n",
    "            'latitude': y,\n",
    "            'longitude': x,\n",
    "            'elevation': cells_geometry.loc[cells_geometry['secondary_climate_file_id'] == clim_id, 'avg_elevation'].mean()\n",
    "            }\n",
    "    }\n",
    "\n",
    "# A \"global\" climate daily / station data needs to be produced so the last climate file will be used\n",
    "climate_data['global'] = climate_data[clim_id]\n",
    "climate_data['global']['climate_station']['output_filepath'] = climate_dir / 'climate_station.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export everything to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reaches and Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_path = watershed_dir / 'cell_data_section.csv'\n",
    "reaches_path = watershed_dir / 'reach_data_section.csv'\n",
    "\n",
    "df_cells.to_csv(cells_path, index=False, float_format='%1.5f')\n",
    "df_reaches_valid.to_csv(reaches_path, index=False, float_format='%1.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GIS layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_geometry.to_file(gis_dir / 'cells_geometry.gpkg', driver='GPKG', index=False)\n",
    "reaches_geometry.to_file(gis_dir / 'reaches_geometry.gpkg', driver='GPKG', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soil Data Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_data_path = general_dir / 'soil_data.csv'\n",
    "soil_layers_data_path = general_dir / 'soil_layers_data.csv'\n",
    "raw_soil_data_path = general_dir / 'raw_soil_data_gNATSGO.csv'\n",
    "\n",
    "df_soil_data.to_csv(soil_data_path, index=False)\n",
    "df_soil_layers_data.to_csv(soil_layers_data_path, index=False)\n",
    "df_raw.to_csv(raw_soil_data_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Management Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_data_path = general_dir / 'crop_data.csv'\n",
    "crop_growth_path = general_dir / 'crop_growth.csv'\n",
    "non_crop_path = general_dir / 'non_crop.csv'\n",
    "management_field_path = general_dir / 'management_field.csv'\n",
    "management_schedule_path = general_dir / 'management_schedule.csv'\n",
    "management_operation_path = general_dir / 'management_oper.csv'\n",
    "roc_path = general_dir / 'runoffcurve.csv'\n",
    "\n",
    "df_mgmt_oper = pyagnps.annagnps.format_mgmt_operation_for_output(df_mgmt_oper)\n",
    "df_mgmt_schd = pyagnps.annagnps.format_mgmt_schedule_for_output(df_mgmt_schd)\n",
    "\n",
    "df_mgmt_crop.to_csv(crop_data_path, index=False)\n",
    "df_mgmt_crop_growth.to_csv(crop_growth_path, index=False)\n",
    "df_mgmt_non_crop.to_csv(non_crop_path, index=False)\n",
    "\n",
    "df_mgmt_field.to_csv(management_field_path, index=False)\n",
    "df_mgmt_schd.to_csv(management_schedule_path, index=False)\n",
    "df_mgmt_oper.to_csv(management_operation_path, index=False)\n",
    "\n",
    "\n",
    "df_roc.to_csv(roc_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clim_id in climate_data:\n",
    "    # Climate Daily\n",
    "    if clim_id == 'global':\n",
    "        climate_path = climate_dir / f\"climate_daily.csv\"\n",
    "    else:\n",
    "        climate_path = climate_dir / f\"climate_daily_{clim_id}.csv\"\n",
    "\n",
    "    climate_data[clim_id]['data'].to_csv(climate_path, index=False, float_format=\"%.3f\")\n",
    "    # Climate Station\n",
    "    pyagnps.climate.generate_climate_station_file(**climate_data[clim_id]['climate_station'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Watershed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_path = watershed_dir / 'watershed_data.csv'\n",
    "\n",
    "pyagnps.utils.write_csv_from_dict(WATERSHED_DATA, output_path=watershed_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global IDs Factors and Flag Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_GLOBAL_FACTORS_FLAGS = pyagnps.constants.DEFAULT_GLOBAL_FACTORS_FLAGS\n",
    "DEFAULT_GLOBAL_FACTORS_FLAGS['Wshd_Storm_Type_ID'] = main_storm_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "globfac_path = simulation_dir / 'globfac.csv'\n",
    "\n",
    "pyagnps.utils.write_csv_from_dict(DEFAULT_GLOBAL_FACTORS_FLAGS, globfac_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Options - Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_OUTPUT_OPTIONS_GLOBAL = pyagnps.constants.DEFAULT_OUTPUT_OPTIONS_GLOBAL\n",
    "\n",
    "outopts_global_path = simulation_dir / 'outopts_global.csv'\n",
    "\n",
    "pyagnps.utils.write_csv_from_dict(DEFAULT_OUTPUT_OPTIONS_GLOBAL, outopts_global_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Options - AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_OUTPUT_OPTIONS_AA = pyagnps.constants.DEFAULT_OUTPUT_OPTIONS_AA\n",
    "\n",
    "outopts_aa_path = simulation_dir / 'outopts_aa.csv'\n",
    "\n",
    "pyagnps.utils.write_csv_from_dict(DEFAULT_OUTPUT_OPTIONS_AA, outopts_aa_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Options - TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_OUTPUT_OPTIONS_TBL = pyagnps.constants.DEFAULT_OUTPUT_OPTIONS_TBL\n",
    "\n",
    "outopts_tbl_path = simulation_dir / 'outopts_tbl.csv'\n",
    "\n",
    "pyagnps.utils.write_csv_from_dict(DEFAULT_OUTPUT_OPTIONS_TBL, outopts_tbl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AnnAGNPS ID file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_ANNAGNPS_ID = pyagnps.constants.DEFAULT_ANNAGNPS_ID\n",
    "\n",
    "annaid_path = simulation_dir / 'annaid.csv'\n",
    "\n",
    "pyagnps.utils.write_csv_from_dict(DEFAULT_ANNAGNPS_ID, annaid_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation Period Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SIM_PERIOD_DATA = pyagnps.constants.DEFAULT_SIM_PERIOD_DATA\n",
    "\n",
    "DEFAULT_SIM_PERIOD_DATA['Simulation_Begin_Year'] = clm.start.year\n",
    "DEFAULT_SIM_PERIOD_DATA['Simulation_Begin_Month'] = clm.start.month\n",
    "DEFAULT_SIM_PERIOD_DATA['Simulation_Begin_Day'] = clm.start.day\n",
    "\n",
    "DEFAULT_SIM_PERIOD_DATA['Simulation_End_Year'] = clm.end.year\n",
    "DEFAULT_SIM_PERIOD_DATA['Simulation_End_Month'] = clm.end.month\n",
    "DEFAULT_SIM_PERIOD_DATA['Simulation_End_Day'] = clm.end.day\n",
    "\n",
    "DEFAULT_SIM_PERIOD_DATA['Rainfall_Fctr'] = weighted_R_fctr\n",
    "DEFAULT_SIM_PERIOD_DATA['10-Year_EI'] = weighted_10_year_EI\n",
    "DEFAULT_SIM_PERIOD_DATA['EI_Number'] = dominant_EI\n",
    "\n",
    "sim_period_path = simulation_dir / 'sim_period.csv'\n",
    "\n",
    "pyagnps.utils.write_csv_from_dict(DEFAULT_SIM_PERIOD_DATA, sim_period_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AnnAGNPS Master File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_input_file_path(output_folder, path_to_file):\n",
    "    path_to_file = Path(path_to_file)\n",
    "    output_folder = Path(output_folder)\n",
    "    relative_path = str(path_to_file.relative_to(output_folder))\n",
    "    relative_path = relative_path.replace('\\\\', '/')\n",
    "    relative_path = f\"./{relative_path}\"\n",
    "    return relative_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_file = {\n",
    "    'AnnAGNPS ID': relative_input_file_path(output_folder, annaid_path),\n",
    "    'Cell Data': relative_input_file_path(output_folder, cells_path),\n",
    "    'Crop Data': relative_input_file_path(output_folder, crop_data_path),\n",
    "    'Crop Growth Data': relative_input_file_path(output_folder, crop_growth_path),\n",
    "    'Global IDs Factors and Flags Data': relative_input_file_path(output_folder, globfac_path),\n",
    "    'Management Field Data': relative_input_file_path(output_folder, management_field_path),\n",
    "    'Management Operation Data': relative_input_file_path(output_folder, management_operation_path),\n",
    "    'Management Schedule Data': relative_input_file_path(output_folder, management_schedule_path),\n",
    "    'Non-Crop Data': relative_input_file_path(output_folder, non_crop_path),\n",
    "    'Reach Data': relative_input_file_path(output_folder, reaches_path),\n",
    "    'Runoff Curve Number Data': relative_input_file_path(output_folder, roc_path),\n",
    "    'Simulation Period Data': relative_input_file_path(output_folder, sim_period_path),\n",
    "    'Soil Data': relative_input_file_path(output_folder, soil_data_path),\n",
    "    'Soil Layer Data': relative_input_file_path(output_folder, soil_layers_data_path),\n",
    "    'Watershed Data': relative_input_file_path(output_folder, watershed_path),\n",
    "    'Output Options - Global': relative_input_file_path(output_folder, outopts_global_path),\n",
    "    'Output Options - AA': relative_input_file_path(output_folder, outopts_aa_path),\n",
    "    'Output Options - TBL': relative_input_file_path(output_folder, outopts_tbl_path),\n",
    "    'CLIMATE DATA - DAILY': relative_input_file_path(output_folder, climate_dir / 'climate_daily.csv'),\n",
    "    'CLIMATE DATA - STATION': relative_input_file_path(output_folder, climate_dir / 'climate_station.csv')\n",
    "    # 'Output Options - Reach'\n",
    "}\n",
    "\n",
    "df_master = pd.DataFrame({\n",
    "    'Data Section ID': master_file.keys(),\n",
    "    'File Name': master_file.values()})\n",
    "\n",
    "df_master.to_csv(output_folder / 'annagnps_master.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AnnAGNPS.fil file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "annagnps_fil = output_folder / 'AnnAGNPS.fil'\n",
    "annagnps_fil.write_text('annagnps_master.csv');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
