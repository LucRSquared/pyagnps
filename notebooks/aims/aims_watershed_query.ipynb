{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIMS Watershed Query: AnnAGNPS files preparation\n",
    "This notebook replicates the data flow of what a user would do when clicking on the AIMS web interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "import pyagnps\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sqlalchemy import URL, create_engine, text as sql_text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User input here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlet coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lon, lat = -89.92829, 32.52256 # Upper Pearl River upstream of reservoir\n",
    "lon, lat = -89.96793, 32.38881 # Pelahatchie Creek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time bounds and climate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_method = 'nldas2' # valid options ares 'nldas2', 'cmip5'\n",
    "\n",
    "# Time period in YYYY-MM-DD format (both bounds included)\n",
    "startDate=\"2010-01-01\" \n",
    "endDate=\"2020-12-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = Path('C:/Users/Luc/Desktop/pelahatchie_creek')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths to useful static files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database credentials\n",
    "credentials = Path(\"../../inputs/db_credentials.json\")\n",
    "\n",
    "# GeoPackage that contains the centroid of each NLDAS-2 grid\n",
    "path_nldas_grid_centroids = Path(\"D:/AIMS/Datasets/Climate/NLDAS2/NLDAS2_GRID_CENTROIDS_epsg4326.gpkg\")\n",
    "# path_nldas_grid_centroids = Path(\"C:/Users/Luc/projects/pyagnps/inputs/climate/NLDAS2_GRID_CENTROIDS_epsg4326.gpkg\")\n",
    "\n",
    "# Path to root folder containing variables of the CMIP5 MACAv2METDATA\n",
    "path_to_cmip5_historical_and_rcp45 = Path(\"D:/AIMS/Datasets/Climate/CMIP/CMIP5/MACAv2METDATA/CNRM-CM5/r1i1p1/\")\n",
    "path_to_cmip5_raster_points_clim_id = path_to_cmip5_historical_and_rcp45 / \"cmip5_maca_v2_metdata_pts_clim_ids.gpkg\"\n",
    "\n",
    "# Path to SCS Storm Types\n",
    "path_to_scs_storm_types = Path('D:/AIMS/Datasets/Climate/TR-55/scs_storm_types.gpkg')\n",
    "\n",
    "# Path to RUSLE2 Precipitation Zones\n",
    "path_to_precip_zones = Path('D:/AIMS/Datasets/Management/RUSLE2_Climate/RUSLE2-Climate-Data-20231117/precip_zones_RUSLE2_cleaned_manually_extrapolated_pchip_linear_US_units.gpkg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main process starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATABASE SETUP\n",
    "with open(credentials, \"r\") as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "user = credentials[\"user\"]\n",
    "password = credentials[\"password\"]\n",
    "host = credentials[\"host\"]\n",
    "port = credentials[\"port\"]\n",
    "database = credentials[\"database\"]\n",
    "\n",
    "url_object = URL.create(\n",
    "    \"postgresql\",\n",
    "    username=user,\n",
    "    password=password,\n",
    "    host=host,\n",
    "    port=port,\n",
    "    database=database\n",
    ")\n",
    "\n",
    "# create a SQLAlchemy engine object\n",
    "engine = create_engine(url_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "def make_annagnps_inputs_dirs(output_folder, subdirs=['general', 'climate', 'simulation', 'watershed', 'GIS']):\n",
    "    subdirs_paths = []\n",
    "    for subdir in subdirs:\n",
    "        category_dir = output_folder / subdir\n",
    "        category_dir.mkdir(exist_ok=True)\n",
    "        subdirs_paths.append(category_dir)\n",
    "    return subdirs_paths\n",
    "        \n",
    "\n",
    "general_dir, \\\n",
    "climate_dir, \\\n",
    "simulation_dir, \\\n",
    "watershed_dir, \\\n",
    "gis_dir = make_annagnps_inputs_dirs(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify T-HUC containing the watershed of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "thuc = pd.read_sql_query(sql_text(f\"SELECT thuc_near_run_id_tr({lon},{lat})\"),con=engine.connect())\n",
    "thuc_id = thuc.iloc[0].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query reach and cell data sections along with their geometries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cells geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_query = f\"SELECT geom, cell_id FROM thuc_cell_geo_tr({lon},{lat}, '{thuc_id}')\"\n",
    "\n",
    "cells_geometry = gpd.read_postgis(sql=sql_text(cells_query), con=engine.connect(), geom_col='geom')\n",
    "cells_list = cells_geometry['cell_id'].unique() # List of cell_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reach Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaches_query = f\"SELECT geom, reach_id FROM thuc_reach_geo_tr({lon},{lat}, '{thuc_id}')\"\n",
    "\n",
    "reaches_geometry = gpd.read_postgis(sql=sql_text(reaches_query), con=engine.connect(), geom_col='geom')\n",
    "reaches_list = reaches_geometry['reach_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell Data Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM thuc_{thuc_id}_annagnps_cell_data_section WHERE cell_id in {*cells_list,}\"\n",
    "\n",
    "df_cells = pd.read_sql_query(sql=sql_text(query), con=engine.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reach Data Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM thuc_{thuc_id}_annagnps_reach_data_section WHERE reach_id in {*reaches_list,}\"\n",
    "\n",
    "df_reaches = pd.read_sql_query(sql=sql_text(query), con=engine.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make reach data section \"valid\" for AnnAGNPS i.e. add an \"OUTLET\" row at the top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_reaches_valid(df_reaches):\n",
    "    reaches = set(df_reaches['reach_id'])\n",
    "    receiving_reaches = set(df_reaches['receiving_reach'])\n",
    "\n",
    "    outlet_reach = list(receiving_reaches - reaches)[0]\n",
    "    # print(f\"Outlet reach: {outlet_reach}\")\n",
    "\n",
    "    outlet_row = df_reaches[df_reaches['receiving_reach']==outlet_reach].copy()\n",
    "    outlet_row['reach_id'] = outlet_reach\n",
    "    outlet_row['receiving_reach'] = 'OUTLET'\n",
    "    outlet_row['length'] = 0\n",
    "\n",
    "    df_reaches_valid = pd.concat([outlet_row, df_reaches], ignore_index=True)\n",
    "    return df_reaches_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reaches_valid = make_df_reaches_valid(df_reaches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join data sections with their respective geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_geometry = cells_geometry.merge(df_cells, on='cell_id')\n",
    "reaches_geometry = reaches_geometry.merge(df_reaches, on='reach_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Soil data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query soil_data and soil_layers_daya for matching soil_id as well as raw soil data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_ids_list = df_cells['soil_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_soil = f\"\"\"SELECT * FROM usa_valid_soil_data WHERE \"Soil_ID\" in {*soil_ids_list,}\"\"\"\n",
    "query_soil_layers = f\"\"\"SELECT * FROM usa_valid_soil_layers_data WHERE \"Soil_ID\" in {*soil_ids_list,}\"\"\"\n",
    "query_raw = f\"\"\"SELECT * FROM raw_nrcs_soil_data WHERE \"mukey\" in {*soil_ids_list,}\"\"\"\n",
    "\n",
    "df_soil_data = pd.read_sql_query(sql=sql_text(query_soil), con=engine.connect())\n",
    "df_soil_layers_data = pd.read_sql_query(sql=sql_text(query_soil_layers), con=engine.connect())\n",
    "df_raw = pd.read_sql_query(sql=sql_text(query_raw), con=engine.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Management Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Management Field IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt_field_ids_list = df_cells['mgmt_field_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field_ID</th>\n",
       "      <th>Landuse_Type_ID</th>\n",
       "      <th>Mgmt_Schd_ID</th>\n",
       "      <th>Greg_Yr_for_1st_Yr_of_Rotation</th>\n",
       "      <th>Percent_Rock_Cover</th>\n",
       "      <th>Interrill_Erosion_Code</th>\n",
       "      <th>Random_Roughness</th>\n",
       "      <th>Terrace_Horizontal_Distance</th>\n",
       "      <th>Terrace_Grade</th>\n",
       "      <th>Tile_Drain_ID</th>\n",
       "      <th>Input_Units_Code</th>\n",
       "      <th>CDL_Category</th>\n",
       "      <th>CDL_Value</th>\n",
       "      <th>Modified_CDL_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corn</td>\n",
       "      <td>CROPLAND</td>\n",
       "      <td>Corn</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Corn</td>\n",
       "      <td>1</td>\n",
       "      <td>Corn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cotton</td>\n",
       "      <td>CROPLAND</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>2</td>\n",
       "      <td>Cotton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Developed_Open_Space</td>\n",
       "      <td>URBAN</td>\n",
       "      <td>Developed_Open_Space</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Developed/Open Space</td>\n",
       "      <td>121</td>\n",
       "      <td>Developed_Open_Space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fallow_Idle_Cropland</td>\n",
       "      <td>PASTURE</td>\n",
       "      <td>Fallow_Idle_Cropland</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Fallow/Idle Cropland</td>\n",
       "      <td>61</td>\n",
       "      <td>Fallow_Idle_Cropland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grassland_Pasture</td>\n",
       "      <td>CROPLAND</td>\n",
       "      <td>Grassland_Pasture</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Grassland/Pasture</td>\n",
       "      <td>176</td>\n",
       "      <td>Grassland_Pasture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Field_ID Landuse_Type_ID          Mgmt_Schd_ID  \\\n",
       "0                  Corn        CROPLAND                  Corn   \n",
       "1                Cotton        CROPLAND                Cotton   \n",
       "2  Developed_Open_Space           URBAN  Developed_Open_Space   \n",
       "3  Fallow_Idle_Cropland         PASTURE  Fallow_Idle_Cropland   \n",
       "4     Grassland_Pasture        CROPLAND     Grassland_Pasture   \n",
       "\n",
       "  Greg_Yr_for_1st_Yr_of_Rotation Percent_Rock_Cover Interrill_Erosion_Code  \\\n",
       "0                           None               None                   None   \n",
       "1                           None               None                   None   \n",
       "2                           None               None                   None   \n",
       "3                           None               None                   None   \n",
       "4                           None               None                   None   \n",
       "\n",
       "  Random_Roughness Terrace_Horizontal_Distance Terrace_Grade Tile_Drain_ID  \\\n",
       "0             None                        None          None          None   \n",
       "1             None                        None          None          None   \n",
       "2             None                        None          None          None   \n",
       "3             None                        None          None          None   \n",
       "4             None                        None          None          None   \n",
       "\n",
       "   Input_Units_Code          CDL_Category  CDL_Value Modified_CDL_Category  \n",
       "0                 1                  Corn          1                  Corn  \n",
       "1                 1                Cotton          2                Cotton  \n",
       "2                 1  Developed/Open Space        121  Developed_Open_Space  \n",
       "3                 1  Fallow/Idle Cropland         61  Fallow_Idle_Cropland  \n",
       "4                 1     Grassland/Pasture        176     Grassland_Pasture  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_mgmt_field_data = f\"\"\"SELECT * FROM annagnps_mgmt_field WHERE \"Field_ID\" in {*mgmt_field_ids_list,}\"\"\"\n",
    "df_mgmt_field = pd.read_sql_query(sql=sql_text(query_mgmt_field_data), con=engine.connect())\n",
    "df_mgmt_field.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get matching Management Schedule IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt_schedule_ids_list = df_mgmt_field['Mgmt_Schd_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_mgmt_field_data = f\"\"\"SELECT * FROM annagnps_mgmt_schd WHERE \"Mgmt_Schd_ID\" in {*mgmt_schedule_ids_list,}\"\"\"\n",
    "df_mgmt_schd = pd.read_sql_query(sql=sql_text(query_mgmt_field_data), con=engine.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get matching Crop, Non-Crop, Management Operation, and Runoff Curve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgmt_crop_ids_list     = df_mgmt_schd['New_Crop_ID'].dropna().unique()\n",
    "mgmt_non_crop_ids_list = df_mgmt_schd['New_Non-Crop_ID'].dropna().unique()\n",
    "mgmt_oper_ids_list     = df_mgmt_schd['Mgmt_Operation_ID'].dropna().unique()\n",
    "roc_ids_list           = df_mgmt_schd['Curve_Number_ID'].dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_mgmt_crop_data        = f\"\"\"SELECT * FROM annagnps_crop WHERE \"Crop_ID\" in {*mgmt_crop_ids_list,}\"\"\"\n",
    "query_mgmt_crop_growth_data = f\"\"\"SELECT * FROM annagnps_crop_growth WHERE \"Crop_Growth_ID\" in {*mgmt_crop_ids_list,}\"\"\"\n",
    "\n",
    "query_mgmt_non_crop_data    = f\"\"\"SELECT * FROM annagnps_non_crop WHERE \"Non-Crop_ID\" in {*mgmt_non_crop_ids_list,}\"\"\"\n",
    "query_mgmt_oper_data        = f\"\"\"SELECT * FROM annagnps_mgmt_oper WHERE \"Mgmt_Operation_ID\" in {*mgmt_oper_ids_list,}\"\"\"\n",
    "\n",
    "query_roc_data              = f\"\"\"SELECT * FROM annagnps_runoff_curve WHERE \"Curve_Number_ID\" in {*roc_ids_list,}\"\"\"\n",
    "\n",
    "df_mgmt_crop        = pd.read_sql_query(sql=sql_text(query_mgmt_crop_data), con=engine.connect())\n",
    "df_mgmt_crop_growth = pd.read_sql_query(sql=sql_text(query_mgmt_crop_growth_data), con=engine.connect())\n",
    "df_mgmt_non_crop    = pd.read_sql_query(sql=sql_text(query_mgmt_non_crop_data), con=engine.connect())\n",
    "df_mgmt_oper        = pd.read_sql_query(sql=sql_text(query_mgmt_oper_data), con=engine.connect())\n",
    "df_roc              = pd.read_sql_query(sql=sql_text(query_roc_data), con=engine.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watershed scale variables - Simulation Period Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Water boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = cells_geometry[['geom']].copy(deep=True)\n",
    "bounds.geometry = bounds.geometry.buffer(0.00001)\n",
    "bounds = bounds.dissolve()\n",
    "bounds = bounds.to_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Watershed SCS Storm Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "scs_storm_types = gpd.read_file(path_to_scs_storm_types)\n",
    "scs_storm_types = scs_storm_types.to_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_scs = bounds.overlay(scs_storm_types)\n",
    "bounds_scs['area'] = bounds_scs.geometry.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_storm_type = bounds_scs.loc[bounds_scs['area'].argmax(), 'SCS Zone Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10_Year_EI, EI_Zone, R_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_zones = gpd.read_file(path_to_precip_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUSLE_REQ</th>\n",
       "      <th>REC_LINK</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>Precip_Zone</th>\n",
       "      <th>EI_Zone</th>\n",
       "      <th>Annual_PPT</th>\n",
       "      <th>R_factor</th>\n",
       "      <th>Max_Eros_Density</th>\n",
       "      <th>10_year_24_hr_ppt</th>\n",
       "      <th>10_year_EI</th>\n",
       "      <th>Notes</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>min_ppt_precip_zone</th>\n",
       "      <th>max_ppt_precip_zone</th>\n",
       "      <th>mid_ppt_precip_zone</th>\n",
       "      <th>geometry</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28123</td>\n",
       "      <td>1.693727</td>\n",
       "      <td>0.151541</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Scott</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US_106</td>\n",
       "      <td>57.688610</td>\n",
       "      <td>478.823513</td>\n",
       "      <td>11.817286</td>\n",
       "      <td>6.6</td>\n",
       "      <td>156.024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((-89.74364 32.41763, -89.74364 32.417...</td>\n",
       "      <td>0.008451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28121</td>\n",
       "      <td>2.459352</td>\n",
       "      <td>0.199821</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Rankin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US_106</td>\n",
       "      <td>56.440866</td>\n",
       "      <td>470.266014</td>\n",
       "      <td>11.847279</td>\n",
       "      <td>6.7</td>\n",
       "      <td>158.790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((-89.95006 32.31314, -89.95006 32.313...</td>\n",
       "      <td>0.043841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RUSLE_REQ REC_LINK  Shape_Leng  Shape_Area        State  County Precip_Zone  \\\n",
       "0       NaN    28123    1.693727    0.151541  Mississippi   Scott         NaN   \n",
       "1       NaN    28121    2.459352    0.199821  Mississippi  Rankin         NaN   \n",
       "\n",
       "  EI_Zone  Annual_PPT    R_factor  Max_Eros_Density  10_year_24_hr_ppt  \\\n",
       "0  US_106   57.688610  478.823513         11.817286                6.6   \n",
       "1  US_106   56.440866  470.266014         11.847279                6.7   \n",
       "\n",
       "   10_year_EI  Notes  GEOID  min_ppt_precip_zone  max_ppt_precip_zone  \\\n",
       "0     156.024    NaN  28123                  NaN                  NaN   \n",
       "1     158.790    NaN  28121                  NaN                  NaN   \n",
       "\n",
       "   mid_ppt_precip_zone                                           geometry  \\\n",
       "0                  NaN  POLYGON ((-89.74364 32.41763, -89.74364 32.417...   \n",
       "1                  NaN  POLYGON ((-89.95006 32.31314, -89.95006 32.313...   \n",
       "\n",
       "       area  \n",
       "0  0.008451  \n",
       "1  0.043841  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds_precip = bounds.overlay(precip_zones)\n",
    "bounds_precip['area'] = bounds_precip.geometry.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_R_fctr = (bounds_precip['area'] * bounds_precip['R_factor']).sum() / bounds_precip['area'].sum()\n",
    "weighted_10_year_EI = (bounds_precip['area'] * bounds_precip['10_year_EI']).sum() / bounds_precip['area'].sum()\n",
    "\n",
    "dominant_EI = bounds_precip.loc[bounds_precip['area'].argmax(), 'EI_Zone']\n",
    "\n",
    "if dominant_EI == 'default':\n",
    "    dominant_EI = pyagnps.constants.DEFAULT_EI_NUMBER # 100 \n",
    "else:\n",
    "    dominant_EI = int(dominant_EI.replace('US_',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate climate files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get watershed centroid computed in terms of lat and lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /!\\ This centroid is computed in degrees coordinates\n",
    "lon0, lat0 = cells_geometry.dissolve().centroid.x[0], cells_geometry.dissolve().centroid.y[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset cells secondary climate file id (just in case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_geometry['secondary_climate_file_id'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using NLDAS-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the NLDAS-2 grid ID nearest to each cell and populate it in the `secondary_climate_file_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if climate_method == 'nldas2':\n",
    "    nldas_centroids = gpd.read_file(path_nldas_grid_centroids)\n",
    "    cells_geometry = cells_geometry.sjoin_nearest(nldas_centroids)\n",
    "    cells_geometry['secondary_climate_file_id'] = cells_geometry['nldas2_grid_ID']\n",
    "    cells_geometry.drop(columns=['nldas2_grid_ID', 'index_right'], inplace=True)\n",
    "\n",
    "    secondary_climate_ids = cells_geometry.loc[:,['cell_id', 'secondary_climate_file_id']]\\\n",
    "                            .drop_duplicates(subset='cell_id')\\\n",
    "                            .set_index('cell_id')\n",
    "    \n",
    "    # Generate climate data for the unique NLDAS-2 grid ID featuring in the watershed \n",
    "    climate_station_points = nldas_centroids[nldas_centroids['nldas2_grid_ID'].isin(cells_geometry['secondary_climate_file_id'].unique())]\n",
    "    climate_station_points = climate_station_points.to_crs('epsg:4326')\n",
    "\n",
    "    # Update df_cells with data in secondary_climate_ids\n",
    "    if df_cells.index.name != 'cell_id':\n",
    "        df_cells = df_cells.set_index('cell_id')\n",
    "\n",
    "    df_cells.update(secondary_climate_ids)\n",
    "    df_cells = df_cells.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using CMIP5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CMIP5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if climate_method == 'cmip5':\n",
    "    clm = pyagnps.climate.ClimateAnnAGNPSCoords(coords=None,\n",
    "                                                start=startDate,\n",
    "                                                end=endDate)\n",
    "\n",
    "    clm.read_cmip5_maca_data(path_to_cmip5_historical_and_rcp45.glob(\"*/*.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate or load geopackage file containing the centroids of each raster points of the CMIP5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if climate_method == 'cmip5':\n",
    "    if path_to_cmip5_raster_points_clim_id.exists():\n",
    "        print('Reading points and clim_id of CMIP5 MACAv2METDATA')\n",
    "        cmip_pts = gpd.read_file(path_to_cmip5_raster_points_clim_id)\n",
    "    else:\n",
    "        # Generate all the possible pairs of points\n",
    "        print('Generating points and clim_id of CMIP5 MACAv2METDATA')\n",
    "        lat_vals = clm.ds['lat'].values\n",
    "        lon_vals = clm.ds['lon'].values - 360 # For CMIP6 and CMIP5 the longitude needs to be in the [0, 360[ range, here we bring it back in the -180, 180\n",
    "\n",
    "        all_lon_lat_pairs = list(itertools.product(lon_vals, lat_vals))\n",
    "\n",
    "        lon_values, lat_values = zip(*all_lon_lat_pairs)\n",
    "\n",
    "        pts = gpd.points_from_xy(x=lon_values, y=lat_values, crs=4326)\n",
    "        cmip_pts = gpd.GeoDataFrame(geometry=pts, crs=4326)\n",
    "\n",
    "        cmip_pts['clim_id'] = cmip_pts['geometry'].apply(lambda geom: clm.generate_cmip_lon_lat_secondary_climate_id((geom.x, geom.y)))\n",
    "\n",
    "        cmip_pts.to_file(path_to_cmip5_raster_points_clim_id, driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning secondary climate id for every cell based on the CMIP5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if climate_method == 'cmip5':\n",
    "\n",
    "    cells_geometry = cells_geometry.sjoin_nearest(cmip_pts)\n",
    "    cells_geometry['secondary_climate_file_id'] = cells_geometry['clim_id']\n",
    "    cells_geometry.drop(columns=['clim_id', 'index_right'], inplace=True)\n",
    "\n",
    "\n",
    "    secondary_climate_ids = cells_geometry.loc[:,['cell_id', 'secondary_climate_file_id']]\\\n",
    "                                .drop_duplicates(subset='cell_id')\\\n",
    "                                .set_index('cell_id')\n",
    "    \n",
    "    # List of points for which to extract the climate data for this watershed\n",
    "    climate_station_points = cmip_pts[cmip_pts['clim_id'].isin(secondary_climate_ids['secondary_climate_file_id'])]\n",
    "    climate_station_points = climate_station_points.to_crs('epsg:4326')\n",
    "\n",
    "    # Update df_cells with data in secondary_climate_ids\n",
    "    if df_cells.index.name != 'cell_id':\n",
    "        df_cells = df_cells.set_index('cell_id')\n",
    "\n",
    "    df_cells.update(secondary_climate_ids)\n",
    "    df_cells = df_cells.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate climate data dictionary for selected climate source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:14<00:00,  1.80s/it]\n"
     ]
    }
   ],
   "source": [
    "climate_data = {}\n",
    "\n",
    "for feature in tqdm(climate_station_points.iterfeatures(), total=len(climate_station_points)):\n",
    "\n",
    "    x, y = feature['geometry']['coordinates']\n",
    "\n",
    "    if climate_method == 'nldas2':\n",
    "        clim_id = feature['properties']['nldas2_grid_ID']\n",
    "        climate_station_name = f\"NLDAS-2 Grid ID {clim_id}\"\n",
    "\n",
    "        clm = pyagnps.climate.ClimateAnnAGNPSCoords(coords=(x,y), start=startDate, end=endDate, date_mode=\"local\")\n",
    "        df = clm.query_nldas2_generate_annagnps_climate_daily()\n",
    "        \n",
    "    elif climate_method == 'cmip5':\n",
    "        clim_id = feature['properties']['clim_id']\n",
    "        climate_station_name = f\"CMIP5 MACAv2METDATA raster ID {clim_id}\"\n",
    "        \n",
    "        clm.update_coords_start_end_dates(coords=(x,y), start=startDate, end=endDate, date_mode=\"local\")\n",
    "        df = clm.generate_annagnps_daily_climate_data_cmip5_maca()\n",
    "        \n",
    "\n",
    "    climate_data[clim_id] = {\n",
    "        'data': df, # DataFrame containing the climate data\n",
    "        'climate_station': { # Climate station metadata\n",
    "            'output_filepath': climate_dir / f'climate_station_{clim_id}.csv',\n",
    "            'climate_station_name': climate_station_name,\n",
    "            'beginning_climate_date': clm.start.strftime(\"%m/%d/%Y\"),\n",
    "            'ending_climate_date': clm.end.strftime(\"%m/%d/%Y\"),\n",
    "            'latitude': y,\n",
    "            'longitude': x,\n",
    "            'elevation': cells_geometry.loc[cells_geometry['secondary_climate_file_id'] == clim_id, 'avg_elevation'].mean()\n",
    "            }\n",
    "    }\n",
    "\n",
    "# A \"global\" climate daily / station data needs to be produced so the last climate file will be used\n",
    "climate_data['global'] = climate_data[clim_id]\n",
    "climate_data['global']['climate_station']['output_filepath'] = climate_dir / 'climate_station.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export everything to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reaches and Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cells.to_csv(watershed_dir / 'cell_data_section.csv', index=False)\n",
    "df_reaches_valid.to_csv(watershed_dir / 'reach_data_section.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GIS layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_geometry.to_file(gis_dir / 'cells_geometry.gpkg', driver='GPKG', index=False)\n",
    "reaches_geometry.to_file(gis_dir / 'reaches_geometry.gpkg', driver='GPKG', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soil Data Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soil_data.to_csv(general_dir / 'soil_data.csv', index=False)\n",
    "df_soil_layers_data.to_csv(general_dir / 'soil_layers_data.csv', index=False)\n",
    "df_raw.to_csv(general_dir / 'raw_soil_data_gNATSGO.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Management Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mgmt_crop.to_csv(general_dir / 'crop_data.csv', index=False)\n",
    "df_mgmt_crop_growth.to_csv(general_dir / 'crop_growth.csv', index=False)\n",
    "df_mgmt_non_crop.to_csv(general_dir / 'non_crop.csv', index=False)\n",
    "\n",
    "df_mgmt_field.to_csv(general_dir / 'management_field.csv', index=False)\n",
    "df_mgmt_schd.to_csv(general_dir / 'management_schedule.csv', index=False)\n",
    "df_mgmt_oper.to_csv(general_dir / 'management_oper.csv', index=False)\n",
    "\n",
    "\n",
    "df_roc.to_csv(general_dir / 'runoffcurve.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clim_id in climate_data:\n",
    "    # Climate Daily\n",
    "    if clim_id == 'global':\n",
    "        climate_path = climate_dir / f\"climate_daily.csv\"\n",
    "    else:\n",
    "        climate_path = climate_dir / f\"climate_daily_{clim_id}.csv\"\n",
    "\n",
    "    climate_data[clim_id]['data'].to_csv(climate_path, index=False, float_format=\"%.3f\")\n",
    "    # Climate Station\n",
    "    pyagnps.climate.generate_climate_station_file(**climate_data[clim_id]['climate_station'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global IDs Factors and Flag Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_GLOBAL_FACTORS_FLAGS = pyagnps.constants.DEFAULT_GLOBAL_FACTORS_FLAGS\n",
    "DEFAULT_GLOBAL_FACTORS_FLAGS['Wshd_Storm_Type_ID'] = main_storm_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "globfac_path = simulation_dir / 'globfac.csv'\n",
    "\n",
    "pyagnps.utils.write_csv_from_dict(DEFAULT_GLOBAL_FACTORS_FLAGS, globfac_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Options - Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_OUTPUT_OPTIONS_GLOBAL = pyagnps.constants.DEFAULT_OUTPUT_OPTIONS_GLOBAL\n",
    "\n",
    "outopts_global_path = simulation_dir / 'outopts_global.csv'\n",
    "\n",
    "pyagnps.utils.write_csv_from_dict(DEFAULT_OUTPUT_OPTIONS_GLOBAL, outopts_global_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Options - AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_OUTPUT_OPTIONS_AA = pyagnps.constants.DEFAULT_OUTPUT_OPTIONS_AA\n",
    "\n",
    "outopts_aa_path = simulation_dir / 'outopts_aa.csv'\n",
    "\n",
    "pyagnps.utils.write_csv_from_dict(DEFAULT_OUTPUT_OPTIONS_AA, outopts_aa_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Options - TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_OUTPUT_OPTIONS_TBL = pyagnps.constants.DEFAULT_OUTPUT_OPTIONS_TBL\n",
    "\n",
    "outopts_tbl_path = simulation_dir / 'outopts_tbl.csv'\n",
    "\n",
    "pyagnps.utils.write_csv_from_dict(DEFAULT_OUTPUT_OPTIONS_TBL, outopts_tbl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AnnAGNPS ID file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_ANNAGNPS_ID = pyagnps.constants.DEFAULT_ANNAGNPS_ID\n",
    "\n",
    "annaid_path = simulation_dir / 'annaid.csv'\n",
    "\n",
    "pyagnps.utils.write_csv_from_dict(DEFAULT_ANNAGNPS_ID, annaid_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation Period Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SIM_PERIOD_DATA = pyagnps.constants.DEFAULT_SIM_PERIOD_DATA\n",
    "\n",
    "DEFAULT_SIM_PERIOD_DATA['Simulation_Begin_Year'] = clm.start.year\n",
    "DEFAULT_SIM_PERIOD_DATA['Simulation_Begin_Month'] = clm.start.month\n",
    "DEFAULT_SIM_PERIOD_DATA['Simulation_Begin_Day'] = clm.start.day\n",
    "\n",
    "DEFAULT_SIM_PERIOD_DATA['Simulation_End_Year'] = clm.end.year\n",
    "DEFAULT_SIM_PERIOD_DATA['Simulation_End_Month'] = clm.end.month\n",
    "DEFAULT_SIM_PERIOD_DATA['Simulation_End_Day'] = clm.end.day\n",
    "\n",
    "DEFAULT_SIM_PERIOD_DATA['Rainfall_Fctr'] = weighted_R_fctr\n",
    "DEFAULT_SIM_PERIOD_DATA['10-Year_EI'] = weighted_10_year_EI\n",
    "DEFAULT_SIM_PERIOD_DATA['EI_Number'] = dominant_EI\n",
    "\n",
    "sim_period_path = simulation_dir / 'sim_period.csv'\n",
    "\n",
    "pyagnps.utils.write_csv_from_dict(DEFAULT_SIM_PERIOD_DATA, sim_period_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AnnAGNPS Master File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
